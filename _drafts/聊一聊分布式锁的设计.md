title: 聊一聊分布式锁的设计
categories: 分布式
tags: 
- 分布式
- redis
- zookeeper
date: 2016-02-24 00:00:00

---

## 起因

前段时间，看到redis作者发布的一篇文章[《Is Redlock safe?》](http://antirez.com/news/101)，Redlock是redis作者基于redis设计的分布式锁的算法。文章起因是有一位分布式的专家写了一篇文章[《How to do distributed locking》](http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)，质疑Redlock的可靠性。redis作者则在《Is Redlock safe?》文章中给予回应，一来一回甚是精彩。文本就为读者一一解析两位专家的争论。

在了解两位专家的争论前，让我先从我了解的分布式锁一一道来。

## 数据库锁表

我第一次接触分布式锁用的是mysql的锁表。当时我并没有分布式锁的概念。只知道当时有两台交易中心服务器处理相同的业务，每个交易中心处理订单的时候需要保证另一个无法处理。于是用mysql的一个表来控制共享资源。表结构如下：

	CREATE TABLE `lockedOrder` (
	  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主码',
	  `type` tinyint(8) unsigned NOT NULL DEFAULT '0' COMMENT '操作类别',
	  `order_id` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的order_id',
	  `memo` varchar(1024) NOT NULL DEFAULT '',
	  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成',
	  PRIMARY KEY (`id`),
	  UNIQUE KEY `uidx_order_id` (`order_id`) USING BTREE
	) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的订单';
	
order_id记录了订单号，type和memo用来记录下是那种类型的操作锁定的订单，memo用来记录一下操作内容。这张表能完成分布式锁的主要原因正是由于把order_id设置为了`UNIQUE KEY`，所以同一个订单号只能插入一次。于是对锁的竞争就交给了数据库，处理同一个订单号的交易中心把订单号插入表中，数据库保证了只有一个交易中心能插入成功，其他交易中心都会插入失败。lock和unlock的伪代码也非常简单：

	def lock ：
		exec sql: insert into lockedOrder(type,order_id,memo) values (type,order_id,memo)
		if result == true :
			return true
		else :
			return false

	def unlock ：
		exec sql: delete from lockedOrder where order_id='order_id'
		
读者可以发现，这个锁从功能上说有几个问题：

*	数据库锁实现只能是非阻塞锁，即应该为tryLock，是尝试获得锁，如果无法获得则会返回失败。要改成阻塞锁，需要反复执行insert语句直到插入成功。由于交易中心的使用场景，只要一个交易中心处理订单就行了，所以这里不需要使用阻塞锁。
*	这把锁没有过期时间，如果交易中心锁定了订单，但异常宕机后，这个订单就无法锁定了。这里为了让锁能够失效，需要在应用层加上定时任务，去删除过期还未解锁的订单。clear_timeout_lock的伪代码很简单，只要执行一条sql即可。

		def clear_timeout_lock :
			exec sql : delete from lockedOrder where update_time <  ADDTIME(NOW(),'-00:02:00')
			
	这里设置过期时间为2分钟，也是从业务场景考虑的，如果订单处理时间可能超过2分钟的话，这个时候还需要加大。
*	这把锁是不能重入的，意思就是即使一个交易中心获得了锁，在它为解锁前，之后的流程如果有再去获取锁的话还会失败，这样就可能出现死锁。这个问题我们当时没有处理，如果要处理这个问题的话，需要增加字段，在insert的时候，把该交易中心的标识加进来，这样再获取锁的时候， 通过select，看下锁定的人是不是自己。lock的伪代码版本如下：

		def lock ：
			exec sql: insert into lockedOrder(type,order_id,memo) values (type,order_id,memo)
			if result == true :
				return true
			else :
				exec sql : select id from lockedOrder where order_id='order_id' and memo = 'TradeCenterId'
				if count > 0 :
					return true
				else 
					return false
	
	在锁定失败后，看下锁是不是自己，如果是自己，那依然锁定成功。不过这个方法解锁又遇到了困难，第一次unlock就把锁给释放了，后面的流程都是在没锁的情况下完成，就可能出现其他交易中心也获取到这个订单锁，产生冲突。解决这个办法的方法就是给锁加计数器，记录下lock多少次。unlock的时候，只有在lock次数为0后才能删除数据库的记录。
	
可以看出，数据库锁能实现一个简单的避免共享资源被多个系统操作的情况。我以前在盛大的时候，发现盛大特别喜欢用数据库锁。盛大的前辈们会说，盛大基本上实现分布式锁用的都是数据库锁。在并发量不是那么恐怖的情况下，数据库锁的性能也不容易出问题，而且由于数据库的数据具有持久化的特性，一般的应用也足够应付。但是除了上面说的数据库锁的几个功能问题外，数据库锁并没有很好的应付数据库宕机的场景，如果数据库宕机，会带来的整个交易中心无法工作。当时我也没想过这个问题，我们整个交易系统，数据库是个单点，不过数据库实在是太稳定了，两年也没出过任何问题。随着工作经验的积累，构建高可用系统的概念越来越强，系统中是不允许出现单点的。现在想想，通过数据库的同步复制，以及使用vip切换Master就能解决这个问题。

## 缓存锁

后来我开始接触缓存服务，知道很多应用都把缓存作为分布式锁，比如redis。使用缓存作为分布式锁，性能非常强劲，在一些不错的硬件上，redis可以每秒执行10w次，内网延迟不超过1ms，足够满足绝大部分应用的锁定需求。

redis锁定的原理是利用setnx命令，即只有在某个key不存在情况才能set成功该key，这样就达到了多个进程并发去set同一个key，只有一个进程能set成功。


